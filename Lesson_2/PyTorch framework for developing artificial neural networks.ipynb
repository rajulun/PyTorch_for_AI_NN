{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Сгенерировать меньший датасет из 8-10 классов движения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:\\\\GeekBrains\\\\Фреймворк PyTorch для разработки искусственных нейронных сетей\\\\Lesson2\\\\nturgb+d_skeletons\\\\\"\n",
    "#### список отсутсвующих элементов так же будет доступен \n",
    "broken_files_path = \"NTU_RGBD_samples_with_missing_skeletons.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skeleton_Dataset(Dataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, data_path, broken_files_path=None, training_classes=None,\n",
    "                 num_joint = 25, max_frame = 300, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.broken_files_path = broken_files_path\n",
    "        self.training_classes = training_classes\n",
    "        self.training_subjects = training_subjects\n",
    "        self.training_cameras = training_cameras\n",
    "        self.transform = transform\n",
    "        self.read_data(data_path, broken_files_path)\n",
    "        self.build_dataframe()\n",
    "        self.labels = self.data.iloc[:,-1]\n",
    "        \n",
    "        \n",
    "    def read_data(self, data_path, broken_files_path):\n",
    "        labels = []\n",
    "        files = []\n",
    "        action_classes = {}\n",
    "        counter = 0\n",
    "        files_counter = {}\n",
    "\n",
    "        with open(broken_files_path, 'r') as f:\n",
    "            broken_files = f.read().split(\"\\n\")\n",
    "\n",
    "        raw_files = os.listdir(data_path)\n",
    "        num_frames = 0\n",
    "\n",
    "        for filename in raw_files:\n",
    "            if filename not in broken_files:\n",
    "                action_class = int(filename[filename.find('A') + 1:filename.find('A') + 4])\n",
    "                subject_id = int(filename[filename.find('P') + 1:filename.find('P') + 4])\n",
    "                camera_id = int(filename[filename.find('C') + 1:filename.find('C') + 4])\n",
    "                if action_class in training_classes and camera_id in training_cameras:  #and subject_id in training_subjects:\n",
    "                    if action_class in action_classes:\n",
    "                        if files_counter[action_class] < 120:\n",
    "                            files.append([filename,action_classes[action_class]])\n",
    "                            files_counter[action_class] = files_counter[action_class] + 1\n",
    "                    else:\n",
    "                        action_classes.update({action_class : counter})\n",
    "                        files_counter.update({action_class : 1})\n",
    "                        counter+=1\n",
    "                        files.append([filename,action_classes[action_class]])\n",
    "    #                     labels.append([action_class])\n",
    "        print(\"action classes: \", action_classes)\n",
    "        print(\"action files: \", files_counter)\n",
    "        \n",
    "        self.files = files\n",
    "        self.action_classes = action_classes\n",
    "\n",
    "#         return files, action_classes\n",
    "\n",
    "    def get_nonzero_std(self, s): \n",
    "        index = s.sum(-1).sum(-1) != 0  \n",
    "        s = s[index]\n",
    "        if len(s) != 0:\n",
    "            s = s[:, :, 0].std() + s[:, :, 1].std() + s[:, :, 2].std()  \n",
    "        else:\n",
    "            s = 0\n",
    "        return s\n",
    "\n",
    "\n",
    "    def read_skeleton_filter(self, file):\n",
    "        with open(file, 'r') as f:\n",
    "            skeleton_sequence = {}\n",
    "            skeleton_sequence['numFrame'] = int(f.readline())\n",
    "            skeleton_sequence['frameInfo'] = []\n",
    "            for t in range(skeleton_sequence['numFrame']):\n",
    "                frame_info = {}\n",
    "                frame_info['numBody'] = int(f.readline())\n",
    "                frame_info['bodyInfo'] = []\n",
    "\n",
    "                for m in range(frame_info['numBody']):\n",
    "                    body_info = {}\n",
    "                    body_info_key = [\n",
    "                        'bodyID', 'clipedEdges', 'handLeftConfidence',\n",
    "                        'handLeftState', 'handRightConfidence', 'handRightState',\n",
    "                        'isResticted', 'leanX', 'leanY', 'trackingState'\n",
    "                    ]\n",
    "                    body_info = {\n",
    "                        k: float(v)\n",
    "                        for k, v in zip(body_info_key, f.readline().split())\n",
    "                    }\n",
    "                    body_info['numJoint'] = int(f.readline())\n",
    "                    body_info['jointInfo'] = []\n",
    "                    for v in range(body_info['numJoint']):\n",
    "                        joint_info_key = [\n",
    "                            'x', 'y', 'z', 'depthX', 'depthY', 'colorX', 'colorY',\n",
    "                            'orientationW', 'orientationX', 'orientationY',\n",
    "                            'orientationZ', 'trackingState'\n",
    "                        ]\n",
    "                        joint_info = {\n",
    "                            k: float(v)\n",
    "                            for k, v in zip(joint_info_key, f.readline().split())\n",
    "                        }\n",
    "                        body_info['jointInfo'].append(joint_info)\n",
    "                    frame_info['bodyInfo'].append(body_info)\n",
    "                skeleton_sequence['frameInfo'].append(frame_info)\n",
    "        return skeleton_sequence\n",
    "\n",
    "\n",
    "    def read_xyz(self, file, max_body=1, num_joint=25):\n",
    "        seq_info = self.read_skeleton_filter(file)\n",
    "        data = np.zeros((max_body, seq_info['numFrame'], num_joint, 3))\n",
    "        for n, f in enumerate(seq_info['frameInfo']):\n",
    "            for m, b in enumerate(f['bodyInfo']):\n",
    "                for j, v in enumerate(b['jointInfo']):\n",
    "                    if m < max_body and j < num_joint:\n",
    "                        data[m, n, j, :] = [v['x'], v['y'], v['z']]\n",
    "\n",
    "                    else:\n",
    "                        pass\n",
    "        return data\n",
    "\n",
    "\n",
    "    def create_coords_blocks(self, test_file, chonk_len = 45):   \n",
    "        frame_counter = 0\n",
    "        new_labels = []\n",
    "        new_frames = []\n",
    "        blocks = []\n",
    "\n",
    "        test_frames = self.read_xyz(data_path + test_file[0])[0]\n",
    "        label = test_file[1]\n",
    "        slice_len = chonk_len * int(len(test_frames)/chonk_len)\n",
    "\n",
    "\n",
    "        for index in range(len(test_frames[:slice_len])):\n",
    "            frame_counter += 1\n",
    "            new_frames.append(test_frames[index].flatten())\n",
    "            if frame_counter == chonk_len:\n",
    "                frame_counter = 0\n",
    "                blocks.append(np.array(new_frames))\n",
    "                new_labels = new_labels + [label]\n",
    "                new_frames = []\n",
    "        return blocks, new_labels\n",
    "        \n",
    "        \n",
    "        joints_framework = ['neck', 'nose', 'mid_hip',\n",
    "                         'l_sho', 'l_elb',\n",
    "                         'l_wri', 'l_hip',\n",
    "                         'l_knee', 'l_ank',\n",
    "                         'r_sho', 'r_elb',\n",
    "                         'r_wri', 'r_hip',\n",
    "                         'r_kne', 'r_ank',\n",
    "                         'r_eye', 'l_eye',\n",
    "                         'r_ear', 'l_ear']\n",
    "\n",
    "\n",
    "        joints_framework_in_work = ['nose','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_kne','r_ank','neck']\n",
    "        upper_joints_framework = ['nose','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_kne','r_ank','neck']\n",
    "\n",
    "\n",
    "\n",
    "        SKELETON_EDGES = np.array([[11, 10], [10, 9], [9, 0], [0, 3], [3, 4], [4, 5], [0, 6], [6, 7], [7, 8], [0, 12],\n",
    "                                       [12, 13], [13, 14], [1, 14], [1, 15], [15, 16], [1, 17], [17, 18]])\n",
    "        \n",
    "        \n",
    "        \n",
    "        bone_pairs = (\n",
    "            (1, 2), (2, 21), (3, 21), (4, 3), (5, 21), (6, 5),\n",
    "            (7, 6), (8, 7), (9, 21), (10, 9), (11, 10), (12, 11),\n",
    "            (13, 1), (14, 13), (15, 14), (16, 15), (17, 1), (18, 17),\n",
    "            (19, 18), (20, 19), (22, 23), (21, 21), (23, 8), (24, 25),(25, 12)\n",
    "        )\n",
    "\n",
    "        bone_pairs_in_work = (\n",
    "            (1, 14), \n",
    "            (14, 2), (2, 3), (3, 4),\n",
    "            (14, 5), (5, 6), (6, 7), \n",
    "            (14, 8), (8, 9), (9, 10),\n",
    "            (14, 11), (11, 12), (12, 13))\n",
    "\n",
    "\n",
    "        joints_names = ['spinebase', 'spinemid', 'neck', 'head','l_sho', 'l_elb','l_wri','l_hand','r_sho','r_elb', 'r_wri', 'r_hand','l_hip','l_knee','l_ank','l_fool','r_hip','r_knee','r_ank','r_foot','spineshoulder','l_tip','l_thumb','r_tip','r_thunb']\n",
    "        joints_in_work = [ 'head','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_knee','r_ank','spineshoulder']\n",
    "        upper_joints = [ 'head','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_knee','r_ank','spineshoulder']\n",
    "        \n",
    "        \n",
    "        ##### список файлов с лейблами на каждый файл \n",
    "        working_files_with_labels, action_classes = read_data(data_path, broken_files_path)\n",
    "        \n",
    "        LABELS = {v: k for k, v in action_classes.items()}\n",
    "        \n",
    "        \n",
    "#         data = []\n",
    "#         labels = []\n",
    "#         ##########################################################################\n",
    "# #         numbers = {0: 0, 1 : 0, 2 : 0, 3 : 0, 4 :0, 5 :0, 6 :0, 7 :0, 8 :0, 9 :0}#####        \n",
    "#         numbers = {x: 0 for x in range(len(action_classes))}\n",
    "#         ##################################################################\n",
    "#         for file in working_files_with_labels:\n",
    "#             frames_blocks, label = create_coords_blocks(file)\n",
    "#             if label != [] and numbers[label[0]] <= 150:\n",
    "#                 numbers[label[0]] = numbers[label[0]] + len(label)\n",
    "#                 data = data + frames_blocks\n",
    "#                 labels = labels + label\n",
    "#         data_np = np.asarray(data)\n",
    "#         labels_np = np.asarray(labels)\n",
    "\n",
    "#         data_sq = data_np.reshape(len(data_np), -1)\n",
    "#         test_data = pd.DataFrame(data_sq)\n",
    "#         test_labels = pd.DataFrame(labels_np)\n",
    "#         test_data['labels'] = test_labels\n",
    "# #         Сохраним файл\n",
    "#         test_data.to_csv(\"skeletons_classes_1_30.csv\", index = False)\n",
    "    \n",
    "#         self.data = test_data\n",
    "#         self.labels = test_data['labels'].astype('float32')\n",
    "#         self.transform = transform\n",
    "#         self.action_classes = action_classes\n",
    "    \n",
    "    \n",
    "    def build_dataframe(self):\n",
    "        \n",
    "        data = []\n",
    "        labels = []\n",
    "        ##########################################################################\n",
    "        numbers = {v: 0 for k, v in self.action_classes.items()}\n",
    "        ##################################################################\n",
    "        for file in self.files:\n",
    "            frames_blocks, label = self.create_coords_blocks(file)\n",
    "#             print(frames_blocks, label)\n",
    "            if label != [] and numbers[label[0]] <= 150:\n",
    "                numbers[label[0]] = numbers[label[0]] + len(label)\n",
    "                data = data + frames_blocks\n",
    "                labels = labels + label\n",
    "        data_np = np.asarray(data)\n",
    "        labels_np = np.asarray(labels)\n",
    "\n",
    "        data_sq = data_np.reshape(len(data_np), -1)\n",
    "        test_data = pd.DataFrame(data_sq)\n",
    "        test_labels = pd.DataFrame(labels_np)\n",
    "        test_data['labels'] = test_labels\n",
    "        self.LABELS = {v: k for k, v in self.action_classes.items()}\n",
    "        self.data = test_data\n",
    "           \n",
    "    def __len__(self):\n",
    "         return len(self.data)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = np.asarray(self.data.iloc[idx,:-1]).reshape(45,75)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform != None:\n",
    "            item = transform(item)\n",
    "        return (item, label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim,layer_num,batch_first=True)\n",
    "        self.dr = torch.nn.Dropout2d(0.1)\n",
    "        self.fc = torch.nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = inputs\n",
    "        lstm_out,(hn,cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subjects = list(range(0, 28)) #количество людей выполняющих действия\n",
    "training_classes = [8, 10, 22, 23, 27, 21, 32, 5, 3, 16] #классы которые будем использовать для обучения, полный список прдставлен тут https://github.com/shahroudy/NTURGB-D\n",
    "training_cameras = [1, 2, 3] \n",
    "\n",
    "max_body_true = 1\n",
    "max_body_kinect = 1\n",
    "\n",
    "num_joint = 25\n",
    "max_frame = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action classes:  {3: 0, 5: 1, 8: 2, 10: 3, 16: 4, 21: 5, 22: 6, 23: 7, 27: 8, 32: 9}\n",
      "action files:  {3: 120, 5: 120, 8: 120, 10: 120, 16: 120, 21: 120, 22: 120, 23: 120, 27: 120, 32: 120}\n"
     ]
    }
   ],
   "source": [
    "dataset = Skeleton_Dataset(data_path, broken_files_path, training_classes, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Обучить уже существующую модель (предварительно проанализировав какие параметры модели нужно изменить)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.75*len(dataset)), len(dataset) - int(0.75*len(dataset))])\n",
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (lstm): LSTM(75, 128, num_layers=2, batch_first=True)\n",
       "  (dr): Dropout2d(p=0.1)\n",
       "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "n_joints = 25*3\n",
    "LABELS = {x: training_classes[x] for x in range(len(training_classes))}\n",
    "n_categories = len(LABELS)\n",
    "n_layer = 2\n",
    "rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "#     print(output.topk(5))\n",
    "    return {x: training_classes[x] for x in range(len(training_classes))}[category_i], category_i\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 iter : 0 (0m 1s) 2.3069  / 8 ✗ (3)\n",
      "epoch : 7 iter : 45 (3m 45s) 2.3152  / 27 ✗ (10)\n",
      "epoch : 15 iter : 25 (7m 37s) 2.3005  / 8 ✗ (21)\n",
      "epoch : 23 iter : 5 (12m 27s) 2.0696  / 32 ✗ (16)\n",
      "epoch : 30 iter : 50 (16m 17s) 2.0240  / 27 ✗ (10)\n",
      "epoch : 38 iter : 30 (19m 53s) 1.8748  / 22 ✓\n",
      "epoch : 46 iter : 10 (23m 11s) 1.8143  / 32 ✗ (5)\n",
      "epoch : 53 iter : 55 (26m 55s) 1.3228  / 8 ✗ (16)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0007\n",
    "optimizer = optim.SGD(rnn.parameters(),lr=learning_rate,momentum=0.9)\n",
    "\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "counter = 0\n",
    "for epoch in range(60):  \n",
    "    current_loss = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device).type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = rnn(inputs.float())\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        category = {x: training_classes[x] for x in range(len(training_classes))}[int(labels[0])]\n",
    "\n",
    "        if counter % 500 == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n",
    "\n",
    "        \n",
    "        counter = counter + 1\n",
    "    if counter % 100 == 0:\n",
    "        all_losses.append(current_loss / 25)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Изменить модель: посмотреть зависимость от количества LSTM модулей в нашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net_changed(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm1 = torch.nn.LSTM(input_dim, hidden_dim, layer_num,batch_first=True)\n",
    "        self.dr1 = torch.nn.Dropout2d(0.1)\n",
    "        self.lstm2 = torch.nn.LSTM(input_dim, hidden_dim)\n",
    "        self.dr2 = torch.nn.Dropout2d(0.1)\n",
    "        self.fc = torch.nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = inputs\n",
    "        lstm_out1,(hn,cn) = self.lstm1(x)\n",
    "        lstm_out2,(hn,cn) = self.lstm2(x)\n",
    "        out = self.fc(lstm_out2[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net_changed(\n",
       "  (lstm1): LSTM(75, 324, num_layers=2, batch_first=True)\n",
       "  (dr1): Dropout2d(p=0.1)\n",
       "  (lstm2): LSTM(75, 324)\n",
       "  (dr2): Dropout2d(p=0.1)\n",
       "  (fc): Linear(in_features=324, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 324\n",
    "n_joints = 25*3\n",
    "n_categories = len({x: training_classes[x] for x in range(len(training_classes))})\n",
    "n_layer = 2\n",
    "rnn = LSTM_net_changed(n_joints,n_hidden,n_categories,n_layer)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 iter : 0 (0m 0s) 2.3212  / 16 ✗ (5)\n",
      "epoch : 7 iter : 45 (8m 16s) 2.2832  / 32 ✓\n",
      "epoch : 15 iter : 25 (16m 12s) 2.2508  / 27 ✗ (10)\n",
      "epoch : 23 iter : 5 (22m 23s) 2.2576  / 8 ✓\n",
      "epoch : 30 iter : 50 (28m 33s) 2.2260  / 22 ✗ (23)\n",
      "epoch : 38 iter : 30 (35m 25s) 2.0521  / 27 ✓\n",
      "epoch : 46 iter : 10 (41m 43s) 1.7338  / 22 ✓\n",
      "epoch : 53 iter : 55 (47m 42s) 1.8658  / 16 ✓\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0007\n",
    "optimizer = optim.SGD(rnn.parameters(),lr=learning_rate,momentum=0.9)\n",
    "\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "counter = 0\n",
    "for epoch in range(60):  \n",
    "    current_loss = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device).type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = rnn(inputs.float())\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        category = {x: training_classes[x] for x in range(len(training_classes))}[int(labels[0])]\n",
    "\n",
    "        if counter % 500 == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n",
    "\n",
    "        \n",
    "        counter = counter + 1\n",
    "    if counter % 100 == 0:\n",
    "        all_losses.append(current_loss / 25)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
